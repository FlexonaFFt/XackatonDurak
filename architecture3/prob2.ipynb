{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "60f54368",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60f54368",
        "outputId": "ce814d49-9af9-4bca-9b4b-aec1e1b92516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используемое устройство: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно загружено 244303 примеров\n",
            "Размерность признаков: (244303, 10)\n",
            "Максимальный индекс карты: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 3627/3627 [00:19<00:00, 184.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.1615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 3627/3627 [00:18<00:00, 196.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 1.1402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 3627/3627 [00:18<00:00, 192.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 1.1365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 3627/3627 [00:18<00:00, 196.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 1.1336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 3627/3627 [00:18<00:00, 192.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 1.1318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 3627/3627 [00:18<00:00, 192.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 1.1306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 3627/3627 [00:18<00:00, 199.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 1.1290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 3627/3627 [00:18<00:00, 192.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 1.1279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 3627/3627 [00:18<00:00, 200.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 1.1264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 3627/3627 [00:19<00:00, 187.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 1.1256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 3627/3627 [00:18<00:00, 199.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss: 1.1231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 3627/3627 [00:18<00:00, 192.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss: 1.1225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 3627/3627 [00:18<00:00, 199.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss: 1.1196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 3627/3627 [00:18<00:00, 191.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss: 1.1173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 3627/3627 [00:18<00:00, 195.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss: 1.1146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 3627/3627 [00:18<00:00, 192.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss: 1.1120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17: 100%|██████████| 3627/3627 [00:18<00:00, 191.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss: 1.1094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18: 100%|██████████| 3627/3627 [00:18<00:00, 199.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss: 1.1061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19: 100%|██████████| 3627/3627 [00:18<00:00, 191.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss: 1.1037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20: 100%|██████████| 3627/3627 [00:18<00:00, 199.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss: 1.1003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DurakDataset(Dataset):\n",
        "    def __init__(self, games, max_hand_size=6):\n",
        "        self.max_hand_size = max_hand_size\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        # Сначала соберем все возможные карты для кодирования\n",
        "        all_cards = set()\n",
        "        valid_games = []\n",
        "\n",
        "        for game in games:\n",
        "            try:\n",
        "                if isinstance(game['snapshot'], str):\n",
        "                    snapshot = json.loads(game['snapshot'])\n",
        "                else:\n",
        "                    snapshot = game['snapshot']\n",
        "\n",
        "                if 'players' in snapshot and len(snapshot['players']) > 0:\n",
        "                    for player in snapshot['players']:\n",
        "                        if 'hand' in player:\n",
        "                            all_cards.update(player['hand'])\n",
        "                    valid_games.append(snapshot)\n",
        "            except (json.JSONDecodeError, KeyError) as e:\n",
        "                continue\n",
        "\n",
        "        if not valid_games:\n",
        "            raise ValueError(\"Не найдено ни одной валидной игры в датасете\")\n",
        "\n",
        "        # Создаем кодировщик карт\n",
        "        self.card_encoder = {card: idx+1 for idx, card in enumerate(all_cards)}\n",
        "        self.card_encoder['PAD'] = 0\n",
        "\n",
        "        # Подготовка фичей и меток\n",
        "        features = []\n",
        "        labels = []\n",
        "\n",
        "        # Определим фиксированное количество признаков\n",
        "        num_features = self.max_hand_size + 4  # карты + 4 дополнительных признака\n",
        "\n",
        "        for game in valid_games:\n",
        "            trump_suit = game.get('trump', '')[-1] if game.get('trump') else ''\n",
        "            player = game['players'][0]\n",
        "\n",
        "            # Кодируем карты в руке\n",
        "            hand_encoded = [self.card_encoder.get(card, 0) for card in player.get('hand', [])]\n",
        "            hand_encoded += [0] * (self.max_hand_size - len(hand_encoded))\n",
        "\n",
        "            # Собираем все признаки\n",
        "            game_features = hand_encoded.copy()\n",
        "            game_features.extend([\n",
        "                game.get('game_rules', {}).get('game_type', 0),\n",
        "                sum(1 for card in player.get('hand', []) if card[-1] == trump_suit),\n",
        "                len(player.get('hand', [])),\n",
        "                len(game.get('deck', []))\n",
        "            ])\n",
        "\n",
        "            # Проверяем, что количество признаков соответствует ожидаемому\n",
        "            if len(game_features) != num_features:\n",
        "                continue\n",
        "\n",
        "            features.append(game_features)\n",
        "            labels.append(player.get('state', 'unknown'))\n",
        "\n",
        "        # Преобразуем в numpy array с проверкой размерностей\n",
        "        try:\n",
        "            features_array = np.vstack(features).astype(np.float32)\n",
        "        except ValueError as e:\n",
        "            print(\"Ошибка при создании массива признаков:\", e)\n",
        "            print(\"Пример features[0]:\", features[0] if features else \"Нет данных\")\n",
        "            raise\n",
        "\n",
        "        # Нормализация\n",
        "        self.features = self.scaler.fit_transform(features_array)\n",
        "        self.labels = self.label_encoder.fit_transform(labels)\n",
        "\n",
        "        print(f\"Успешно загружено {len(self.labels)} примеров\")\n",
        "        print(f\"Размерность признаков: {self.features.shape}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.FloatTensor(self.features[idx]),\n",
        "            torch.LongTensor([self.labels[idx]])\n",
        "        )\n",
        "\n",
        "class DurakNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=2):\n",
        "        super().__init__()\n",
        "        # Увеличиваем размер словаря для embedding\n",
        "        self.embedding = nn.Embedding(num_embeddings=1000, embedding_dim=16)  # Было 100\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1, bias=False)\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        cards = x[:, :6].long()\n",
        "        # Добавляем ограничение значений для embedding\n",
        "        cards = torch.clamp(cards, 0, self.embedding.num_embeddings - 1)\n",
        "\n",
        "        other_features = x[:, 6:]\n",
        "\n",
        "        cards_embedded = self.embedding(cards)\n",
        "        lstm_input = torch.cat([\n",
        "            cards_embedded,\n",
        "            other_features.unsqueeze(1).expand(-1, 6, -1)\n",
        "        ], dim=2)\n",
        "\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
        "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        return self.fc(context)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Параметры\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 20\n",
        "    HIDDEN_SIZE = 128\n",
        "\n",
        "    # Проверка доступности GPU\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "    # Загрузка данных\n",
        "    dataset = load_dataset(\"neuronetties/durak\")\n",
        "\n",
        "    try:\n",
        "        full_dataset = DurakDataset(dataset[\"train\"])\n",
        "\n",
        "        # Проверка индексов карт\n",
        "        max_card_idx = max(full_dataset.card_encoder.values())\n",
        "        print(f\"Максимальный индекс карты: {max_card_idx}\")\n",
        "\n",
        "        # Разделение данных\n",
        "        train_size = int(0.95 * len(full_dataset))\n",
        "        test_size = len(full_dataset) - train_size\n",
        "\n",
        "        train_dataset, test_dataset = random_split(\n",
        "            full_dataset,\n",
        "            [train_size, test_size],\n",
        "            generator=torch.Generator().manual_seed(42)\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Инициализация модели с учетом размера словаря\n",
        "        model = DurakNN(\n",
        "            input_size=16 + (full_dataset.features.shape[1] - 6),\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            num_classes=len(full_dataset.label_encoder.classes_)\n",
        "        )\n",
        "\n",
        "        # Перемещение модели на GPU\n",
        "        model.to(device)\n",
        "\n",
        "        # Проверка и корректировка embedding\n",
        "        if max_card_idx >= model.embedding.num_embeddings:\n",
        "            print(f\"Корректируем размер embedding слоя с {model.embedding.num_embeddings} до {max_card_idx + 100}\")\n",
        "            model.embedding = nn.Embedding(\n",
        "                num_embeddings=max_card_idx + 100,\n",
        "                embedding_dim=16\n",
        "            ).to(device)  # Перемещение embedding на GPU\n",
        "\n",
        "        optimizer = Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Цикл обучения\n",
        "        for epoch in range(EPOCHS):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "                x, y = batch\n",
        "                x, y = x.to(device), y.to(device)  # Перемещение данных на GPU\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y.squeeze())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "        # Сохранение модели\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'scaler_mean': full_dataset.scaler.mean_,\n",
        "            'scaler_var': full_dataset.scaler.var_,\n",
        "            'card_encoder': full_dataset.card_encoder,\n",
        "            'label_encoder_classes': full_dataset.label_encoder.classes_,\n",
        "            'input_size': model.lstm.input_size,\n",
        "            'device': next(model.parameters()).device\n",
        "        }, 'durak_deep_model_new.pt')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка: {str(e)}\")\n",
        "        print(\"Проверьте структуру данных и попробуйте снова\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "214ec59f",
      "metadata": {
        "id": "214ec59f"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2db8fb30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2db8fb30",
        "outputId": "b48ceca7-7d02-496a-e2a6-c3e8f13a7a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Принято решение: {'type': np.str_('attack'), 'move': '11C'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.serialization import add_safe_globals\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DurakNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=1000, embedding_dim=16)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1, bias=False)\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        cards = x[:, :6].long()\n",
        "        cards = torch.clamp(cards, 0, self.embedding.num_embeddings - 1)\n",
        "        other_features = x[:, 6:]\n",
        "\n",
        "        cards_embedded = self.embedding(cards)\n",
        "        lstm_input = torch.cat([\n",
        "            cards_embedded,\n",
        "            other_features.unsqueeze(1).expand(-1, 6, -1)\n",
        "        ], dim=2)\n",
        "\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
        "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        return self.fc(context)\n",
        "\n",
        "class DurakModel:\n",
        "    def __init__(self, model_path='durak_deep_model_new.pt'):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Файл модели {model_path} не найден\")\n",
        "\n",
        "        try:\n",
        "            # Добавляем разрешенные глобальные переменные перед загрузкой\n",
        "            torch.serialization.add_safe_globals([np._core.multiarray._reconstruct])\n",
        "\n",
        "            # Загружаем модель с weights_only=False для совместимости\n",
        "            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
        "\n",
        "            # Инициализация модели\n",
        "            self.model = DurakNN(\n",
        "                input_size=checkpoint['input_size'],\n",
        "                hidden_size=128,\n",
        "                num_classes=len(checkpoint['label_encoder_classes'])\n",
        "            ).to(self.device)\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.model.eval()\n",
        "\n",
        "            # Восстановление StandardScaler\n",
        "            self.scaler = StandardScaler()\n",
        "            self.scaler.mean_ = checkpoint['scaler_mean']\n",
        "            self.scaler.var_ = checkpoint['scaler_var']\n",
        "            self.scaler.scale_ = np.sqrt(self.scaler.var_)\n",
        "\n",
        "            # Восстановление кодировщиков\n",
        "            self.card_encoder = checkpoint['card_encoder']\n",
        "            self.label_encoder = LabelEncoder()\n",
        "            self.label_encoder.classes_ = checkpoint['label_encoder_classes']\n",
        "\n",
        "            self.reverse_card_encoder = {v:k for k,v in self.card_encoder.items()}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Ошибка загрузки модели. Проверьте:\")\n",
        "            print(f\"1. Существует ли файл {model_path}\")\n",
        "            print(f\"2. Совместима ли версия PyTorch ({torch.__version__})\")\n",
        "            print(f\"3. Полный текст ошибки: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _load_model_alternative(self, model_path):\n",
        "        \"\"\"Альтернативный способ загрузки для старых версий PyTorch\"\"\"\n",
        "        import pickle\n",
        "\n",
        "        with open(model_path, 'rb') as f:\n",
        "            checkpoint = pickle.load(f)\n",
        "\n",
        "        # Преобразуем тензоры если нужно\n",
        "        if 'model_state_dict' in checkpoint:\n",
        "            for k, v in checkpoint['model_state_dict'].items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    checkpoint['model_state_dict'][k] = v.to(self.device)\n",
        "\n",
        "        return checkpoint\n",
        "\n",
        "    def prepare_features(self, game_state, max_hand_size=6):\n",
        "        \"\"\"Подготавливает признаки из состояния игры\"\"\"\n",
        "        # Кодируем карты в руке\n",
        "        hand_encoded = [self.card_encoder.get(card, 0) for card in game_state['player_hand']]\n",
        "        hand_encoded += [0] * (max_hand_size - len(hand_encoded))\n",
        "\n",
        "        # Определяем козырную масть\n",
        "        trump_suit = game_state['trump'][-1] if game_state.get('trump') else ''\n",
        "\n",
        "        # Собираем признаки\n",
        "        features = [\n",
        "            *hand_encoded,\n",
        "            game_state.get('game_type', 0),\n",
        "            sum(1 for card in game_state['player_hand'] if card[-1] == trump_suit),\n",
        "            len(game_state['player_hand']),\n",
        "            len(game_state.get('deck', [])),\n",
        "        ]\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "\n",
        "    def predict_action(self, game_state):\n",
        "        \"\"\"Предсказывает лучшее действие для текущего состояния\"\"\"\n",
        "        features = self.prepare_features(game_state)\n",
        "        features = self.scaler.transform([features])\n",
        "        features_tensor = torch.FloatTensor(features).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model(features_tensor)\n",
        "            action_idx = torch.argmax(output).item()\n",
        "            q_values = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        action = self.label_encoder.inverse_transform([action_idx])[0]\n",
        "        return action, q_values\n",
        "\n",
        "    def choose_card(self, game_state, action_type):\n",
        "        \"\"\"Выбирает конкретную карту для действия\"\"\"\n",
        "        valid_cards = self.get_valid_cards(game_state, action_type)\n",
        "        if not valid_cards:\n",
        "            return None\n",
        "\n",
        "        # Простейшая стратегия: выбираем карту с наименьшим номиналом\n",
        "        if action_type == 'attack':\n",
        "            return min(valid_cards, key=lambda x: (x[:-1], x[-1]))\n",
        "        else:  # defend\n",
        "            trump_suit = game_state['trump'][-1]\n",
        "            attack_card = game_state['table'][-1]['attack_card']['card']\n",
        "\n",
        "            # Сначала пытаемся побить той же мастью\n",
        "            same_suit = [c for c in valid_cards if c[-1] == attack_card[-1] and c[:-1] > attack_card[:-1]]\n",
        "            if same_suit:\n",
        "                return min(same_suit, key=lambda x: x[:-1])\n",
        "\n",
        "            # Если нет - побить козырем\n",
        "            trumps = [c for c in valid_cards if c[-1] == trump_suit]\n",
        "            if trumps:\n",
        "                return min(trumps, key=lambda x: x[:-1])\n",
        "\n",
        "            return None  # Не можем побить\n",
        "\n",
        "    def get_valid_cards(self, game_state, action_type):\n",
        "        \"\"\"Возвращает допустимые карты для действия\"\"\"\n",
        "        if action_type == 'attack':\n",
        "            if not game_state['table']:\n",
        "                return game_state['player_hand']  # Первая атака - любые карты\n",
        "            else:\n",
        "                # Можно подкидывать только карты того же номинала, что уже на столе\n",
        "                table_ranks = {card['attack_card']['card'][:-1] for card in game_state['table']}\n",
        "                return [card for card in game_state['player_hand'] if card[:-1] in table_ranks]\n",
        "        elif action_type == 'defend':\n",
        "            if not game_state['table']:\n",
        "                return []\n",
        "            attack_card = game_state['table'][-1]['attack_card']['card']\n",
        "            trump_suit = game_state['trump'][-1]\n",
        "\n",
        "            valid = []\n",
        "            for card in game_state['player_hand']:\n",
        "                # Можно побить той же мастью и старше\n",
        "                if card[-1] == attack_card[-1] and card[:-1] > attack_card[:-1]:\n",
        "                    valid.append(card)\n",
        "                # Или любым козырем (если атака не козырь)\n",
        "                elif card[-1] == trump_suit and attack_card[-1] != trump_suit:\n",
        "                    valid.append(card)\n",
        "            return valid\n",
        "        return []\n",
        "\n",
        "    def make_decision(self, game_state):\n",
        "        \"\"\"Основной метод для принятия решения\"\"\"\n",
        "        action, q_values = self.predict_action(game_state)\n",
        "\n",
        "        if action in ['attack', 'defend']:\n",
        "            card = self.choose_card(game_state, action)\n",
        "            if card:\n",
        "                return {'type': action, 'move': card}\n",
        "            else:\n",
        "                return {'type': 'take'}  # Если не можем побить - берем\n",
        "        else:\n",
        "            return {'type': action}\n",
        "\n",
        "def save_model(model, scaler, card_encoder, label_encoder, input_size, path='durak_deep_model_new.pt'):\n",
        "    \"\"\"Новый способ сохранения модели, совместимый с PyTorch 2.6+\"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'scaler_mean': scaler.mean_,\n",
        "        'scaler_var': scaler.var_,  # Сохраняем дисперсию вместо scale_\n",
        "        'card_encoder': dict(card_encoder),\n",
        "        'label_encoder_classes': label_encoder.classes_,\n",
        "        'input_size': input_size,\n",
        "        'device': next(model.parameters()).device\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"Модель сохранена в {path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        durak_ai = DurakModel('durak_deep_model_new.pt')\n",
        "\n",
        "        test_state = {\n",
        "            'trump': '10H',\n",
        "            'player_hand': ['9S', '11C', '14H', '12C', '13D'],\n",
        "            'game_type': 0,\n",
        "            'deck': ['11S', '10D', '10C', '12H'],\n",
        "            'table': [],\n",
        "            'opponent_hand_count': 4\n",
        "        }\n",
        "\n",
        "        decision = durak_ai.make_decision(test_state)\n",
        "        print(\"Принято решение:\", decision)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при работе модели: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
