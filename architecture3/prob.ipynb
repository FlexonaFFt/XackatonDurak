{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f54368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flexonafft/Documents/XackatonDurak/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/flexonafft/Documents/XackatonDurak/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно загружено 244303 примеров\n",
      "Размерность признаков: (244303, 10)\n",
      "Максимальный индекс карты: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3627/3627 [00:21<00:00, 170.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3627/3627 [00:22<00:00, 162.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3627/3627 [00:23<00:00, 156.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3627/3627 [00:23<00:00, 153.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3627/3627 [00:23<00:00, 156.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3627/3627 [00:23<00:00, 153.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3627/3627 [00:24<00:00, 148.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3627/3627 [00:24<00:00, 145.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3627/3627 [00:24<00:00, 147.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3627/3627 [00:24<00:00, 145.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 3627/3627 [00:24<00:00, 146.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 3627/3627 [00:24<00:00, 146.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 1.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3627/3627 [00:24<00:00, 145.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 1.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 3627/3627 [00:24<00:00, 145.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 1.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 3627/3627 [00:24<00:00, 145.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 1.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 3627/3627 [00:24<00:00, 146.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 1.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 3627/3627 [00:24<00:00, 145.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 1.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 3627/3627 [00:24<00:00, 147.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 1.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 3627/3627 [00:24<00:00, 145.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 1.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 3627/3627 [00:24<00:00, 146.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DurakDataset(Dataset):\n",
    "    def __init__(self, games, max_hand_size=6):\n",
    "        self.max_hand_size = max_hand_size\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Сначала соберем все возможные карты для кодирования\n",
    "        all_cards = set()\n",
    "        valid_games = []\n",
    "        \n",
    "        for game in games:\n",
    "            try:\n",
    "                if isinstance(game['snapshot'], str):\n",
    "                    snapshot = json.loads(game['snapshot'])\n",
    "                else:\n",
    "                    snapshot = game['snapshot']\n",
    "                    \n",
    "                if 'players' in snapshot and len(snapshot['players']) > 0:\n",
    "                    for player in snapshot['players']:\n",
    "                        if 'hand' in player:\n",
    "                            all_cards.update(player['hand'])\n",
    "                    valid_games.append(snapshot)\n",
    "            except (json.JSONDecodeError, KeyError) as e:\n",
    "                continue\n",
    "        \n",
    "        if not valid_games:\n",
    "            raise ValueError(\"Не найдено ни одной валидной игры в датасете\")\n",
    "        \n",
    "        # Создаем кодировщик карт\n",
    "        self.card_encoder = {card: idx+1 for idx, card in enumerate(all_cards)}\n",
    "        self.card_encoder['PAD'] = 0\n",
    "        \n",
    "        # Подготовка фичей и меток\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        # Определим фиксированное количество признаков\n",
    "        num_features = self.max_hand_size + 4  # карты + 4 дополнительных признака\n",
    "        \n",
    "        for game in valid_games:\n",
    "            trump_suit = game.get('trump', '')[-1] if game.get('trump') else ''\n",
    "            player = game['players'][0]\n",
    "            \n",
    "            # Кодируем карты в руке\n",
    "            hand_encoded = [self.card_encoder.get(card, 0) for card in player.get('hand', [])]\n",
    "            hand_encoded += [0] * (self.max_hand_size - len(hand_encoded))\n",
    "            \n",
    "            # Собираем все признаки\n",
    "            game_features = hand_encoded.copy()\n",
    "            game_features.extend([\n",
    "                game.get('game_rules', {}).get('game_type', 0),\n",
    "                sum(1 for card in player.get('hand', []) if card[-1] == trump_suit),\n",
    "                len(player.get('hand', [])),\n",
    "                len(game.get('deck', []))\n",
    "            ])\n",
    "            \n",
    "            # Проверяем, что количество признаков соответствует ожидаемому\n",
    "            if len(game_features) != num_features:\n",
    "                continue\n",
    "                \n",
    "            features.append(game_features)\n",
    "            labels.append(player.get('state', 'unknown'))\n",
    "        \n",
    "        # Преобразуем в numpy array с проверкой размерностей\n",
    "        try:\n",
    "            features_array = np.vstack(features).astype(np.float32)\n",
    "        except ValueError as e:\n",
    "            print(\"Ошибка при создании массива признаков:\", e)\n",
    "            print(\"Пример features[0]:\", features[0] if features else \"Нет данных\")\n",
    "            raise\n",
    "        \n",
    "        # Нормализация\n",
    "        self.features = self.scaler.fit_transform(features_array)\n",
    "        self.labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        print(f\"Успешно загружено {len(self.labels)} примеров\")\n",
    "        print(f\"Размерность признаков: {self.features.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]),\n",
    "            torch.LongTensor([self.labels[idx]])\n",
    "        )\n",
    "\n",
    "class DurakNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers=2):\n",
    "        super().__init__()\n",
    "        # Увеличиваем размер словаря для embedding\n",
    "        self.embedding = nn.Embedding(num_embeddings=1000, embedding_dim=16)  # Было 100\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cards = x[:, :6].long()\n",
    "        # Добавляем ограничение значений для embedding\n",
    "        cards = torch.clamp(cards, 0, self.embedding.num_embeddings - 1)\n",
    "        \n",
    "        other_features = x[:, 6:]\n",
    "        \n",
    "        cards_embedded = self.embedding(cards)\n",
    "        lstm_input = torch.cat([\n",
    "            cards_embedded,\n",
    "            other_features.unsqueeze(1).expand(-1, 6, -1)\n",
    "        ], dim=2)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        \n",
    "        return self.fc(context)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 20\n",
    "    HIDDEN_SIZE = 128\n",
    "\n",
    "    # Загрузка данных\n",
    "    dataset = load_dataset(\"neuronetties/durak\")\n",
    "    \n",
    "    try:\n",
    "        full_dataset = DurakDataset(dataset[\"train\"])\n",
    "        \n",
    "        # Проверка индексов карт\n",
    "        max_card_idx = max(full_dataset.card_encoder.values())\n",
    "        print(f\"Максимальный индекс карты: {max_card_idx}\")\n",
    "        \n",
    "        # Разделение данных\n",
    "        train_size = int(0.95 * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, test_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Инициализация модели с учетом размера словаря\n",
    "        model = DurakNN(\n",
    "            input_size=16 + (full_dataset.features.shape[1] - 6),\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_classes=len(full_dataset.label_encoder.classes_)\n",
    "        )\n",
    "        \n",
    "        # Проверка и корректировка embedding\n",
    "        if max_card_idx >= model.embedding.num_embeddings:\n",
    "            print(f\"Корректируем размер embedding слоя с {model.embedding.num_embeddings} до {max_card_idx + 100}\")\n",
    "            model.embedding = nn.Embedding(\n",
    "                num_embeddings=max_card_idx + 100,\n",
    "                embedding_dim=16\n",
    "            )\n",
    "\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Цикл обучения\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "                x, y = batch\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Сохранение модели\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'scaler': full_dataset.scaler,\n",
    "            'card_encoder': full_dataset.card_encoder,\n",
    "            'label_encoder': full_dataset.label_encoder,\n",
    "            'input_size': model.lstm.input_size\n",
    "        }, 'durak_deep_model.pt')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {str(e)}\")\n",
    "        print(\"Проверьте структуру данных и попробуйте снова\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ec59f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db8fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при конвертации модели: 'model'\n",
      "Ошибка при работе модели: 'label_encoder_classes'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.serialization import add_safe_globals\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DurakNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=1000, embedding_dim=16)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cards = x[:, :6].long()\n",
    "        cards = torch.clamp(cards, 0, self.embedding.num_embeddings - 1)\n",
    "        other_features = x[:, 6:]\n",
    "        \n",
    "        cards_embedded = self.embedding(cards)\n",
    "        lstm_input = torch.cat([\n",
    "            cards_embedded,\n",
    "            other_features.unsqueeze(1).expand(-1, 6, -1)\n",
    "        ], dim=2)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
    "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        \n",
    "        return self.fc(context)\n",
    "\n",
    "class DurakModel:\n",
    "    def __init__(self, model_path='durak_deep_model.pt'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Альтернативный способ загрузки с обработкой sklearn объектов\n",
    "        try:\n",
    "            # Попробуем загрузить с weights_only=False\n",
    "            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка загрузки модели: {str(e)}\")\n",
    "            print(\"Пробуем альтернативный способ загрузки...\")\n",
    "            checkpoint = self._load_model_alternative(model_path)\n",
    "        \n",
    "        # Инициализация модели\n",
    "        self.model = DurakNN(\n",
    "            input_size=checkpoint['input_size'],\n",
    "            hidden_size=128,\n",
    "            num_classes=len(checkpoint['label_encoder_classes'])\n",
    "        ).to(self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Восстанавливаем scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.mean_ = checkpoint['scaler_mean']\n",
    "        self.scaler.scale_ = checkpoint['scaler_var'] ** 0.5  # scale = sqrt(var)\n",
    "        \n",
    "        # Восстанавливаем кодировщики\n",
    "        self.card_encoder = checkpoint['card_encoder']\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.classes_ = checkpoint['label_encoder_classes']\n",
    "        \n",
    "        self.reverse_card_encoder = {v:k for k,v in self.card_encoder.items()}\n",
    "\n",
    "    def _load_model_alternative(self, model_path):\n",
    "        \"\"\"Альтернативный способ загрузки для старых версий PyTorch\"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        with open(model_path, 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "        \n",
    "        # Преобразуем тензоры если нужно\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            for k, v in checkpoint['model_state_dict'].items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    checkpoint['model_state_dict'][k] = v.to(self.device)\n",
    "        \n",
    "        return checkpoint\n",
    "\n",
    "    def prepare_features(self, game_state, max_hand_size=6):\n",
    "        \"\"\"Подготавливает признаки из состояния игры\"\"\"\n",
    "        # Кодируем карты в руке\n",
    "        hand_encoded = [self.card_encoder.get(card, 0) for card in game_state['player_hand']]\n",
    "        hand_encoded += [0] * (max_hand_size - len(hand_encoded))\n",
    "        \n",
    "        # Определяем козырную масть\n",
    "        trump_suit = game_state['trump'][-1] if game_state.get('trump') else ''\n",
    "        \n",
    "        # Собираем признаки\n",
    "        features = [\n",
    "            *hand_encoded,\n",
    "            game_state.get('game_type', 0),\n",
    "            sum(1 for card in game_state['player_hand'] if card[-1] == trump_suit),\n",
    "            len(game_state['player_hand']),\n",
    "            len(game_state.get('deck', [])),\n",
    "        ]\n",
    "        \n",
    "        return np.array(features, dtype=np.float32)\n",
    "\n",
    "    def predict_action(self, game_state):\n",
    "        \"\"\"Предсказывает лучшее действие для текущего состояния\"\"\"\n",
    "        features = self.prepare_features(game_state)\n",
    "        features = self.scaler.transform([features])\n",
    "        features_tensor = torch.FloatTensor(features).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(features_tensor)\n",
    "            action_idx = torch.argmax(output).item()\n",
    "            q_values = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        action = self.label_encoder.inverse_transform([action_idx])[0]\n",
    "        return action, q_values\n",
    "\n",
    "    def choose_card(self, game_state, action_type):\n",
    "        \"\"\"Выбирает конкретную карту для действия\"\"\"\n",
    "        valid_cards = self.get_valid_cards(game_state, action_type)\n",
    "        if not valid_cards:\n",
    "            return None\n",
    "            \n",
    "        # Простейшая стратегия: выбираем карту с наименьшим номиналом\n",
    "        if action_type == 'attack':\n",
    "            return min(valid_cards, key=lambda x: (x[:-1], x[-1]))\n",
    "        else:  # defend\n",
    "            trump_suit = game_state['trump'][-1]\n",
    "            attack_card = game_state['table'][-1]['attack_card']['card']\n",
    "            \n",
    "            # Сначала пытаемся побить той же мастью\n",
    "            same_suit = [c for c in valid_cards if c[-1] == attack_card[-1] and c[:-1] > attack_card[:-1]]\n",
    "            if same_suit:\n",
    "                return min(same_suit, key=lambda x: x[:-1])\n",
    "            \n",
    "            # Если нет - побить козырем\n",
    "            trumps = [c for c in valid_cards if c[-1] == trump_suit]\n",
    "            if trumps:\n",
    "                return min(trumps, key=lambda x: x[:-1])\n",
    "            \n",
    "            return None  # Не можем побить\n",
    "\n",
    "    def get_valid_cards(self, game_state, action_type):\n",
    "        \"\"\"Возвращает допустимые карты для действия\"\"\"\n",
    "        if action_type == 'attack':\n",
    "            if not game_state['table']:\n",
    "                return game_state['player_hand']  # Первая атака - любые карты\n",
    "            else:\n",
    "                # Можно подкидывать только карты того же номинала, что уже на столе\n",
    "                table_ranks = {card['attack_card']['card'][:-1] for card in game_state['table']}\n",
    "                return [card for card in game_state['player_hand'] if card[:-1] in table_ranks]\n",
    "        elif action_type == 'defend':\n",
    "            if not game_state['table']:\n",
    "                return []\n",
    "            attack_card = game_state['table'][-1]['attack_card']['card']\n",
    "            trump_suit = game_state['trump'][-1]\n",
    "            \n",
    "            valid = []\n",
    "            for card in game_state['player_hand']:\n",
    "                # Можно побить той же мастью и старше\n",
    "                if card[-1] == attack_card[-1] and card[:-1] > attack_card[:-1]:\n",
    "                    valid.append(card)\n",
    "                # Или любым козырем (если атака не козырь)\n",
    "                elif card[-1] == trump_suit and attack_card[-1] != trump_suit:\n",
    "                    valid.append(card)\n",
    "            return valid\n",
    "        return []\n",
    "\n",
    "    def make_decision(self, game_state):\n",
    "        \"\"\"Основной метод для принятия решения\"\"\"\n",
    "        action, q_values = self.predict_action(game_state)\n",
    "        \n",
    "        if action in ['attack', 'defend']:\n",
    "            card = self.choose_card(game_state, action)\n",
    "            if card:\n",
    "                return {'type': action, 'move': card}\n",
    "            else:\n",
    "                return {'type': 'take'}  # Если не можем побить - берем\n",
    "        else:\n",
    "            return {'type': action}\n",
    "        \n",
    "def save_model(model, scaler, card_encoder, label_encoder, input_size, path='durak_deep_model_new.pt'):\n",
    "    \"\"\"Новый способ сохранения модели, совместимый с PyTorch 2.6+\"\"\"\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'scaler_mean': scaler.mean_,\n",
    "        'scaler_var': scaler.var_,  # Сохраняем дисперсию вместо scale_\n",
    "        'card_encoder': dict(card_encoder),\n",
    "        'label_encoder_classes': label_encoder.classes_,\n",
    "        'input_size': input_size,\n",
    "        'device': next(model.parameters()).device\n",
    "    }\n",
    "        \n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Модель сохранена в {path}\")\n",
    "\n",
    "# Пример использования:\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Сначала пересохраните модель в новом формате (если старая модель есть)\n",
    "    try:\n",
    "        # Загрузка старой модели\n",
    "        old_checkpoint = torch.load('durak_deep_model.pt', map_location='cpu', weights_only=False)\n",
    "        \n",
    "        # Создание новых объектов\n",
    "        new_scaler = StandardScaler()\n",
    "        new_scaler.mean_ = old_checkpoint['scaler'].mean_\n",
    "        new_scaler.var_ = old_checkpoint['scaler'].var_\n",
    "        \n",
    "        # Сохранение в новом формате\n",
    "        save_model(\n",
    "            model=old_checkpoint['model'],\n",
    "            scaler=new_scaler,\n",
    "            card_encoder=old_checkpoint['card_encoder'],\n",
    "            label_encoder=old_checkpoint['label_encoder'],\n",
    "            input_size=old_checkpoint['input_size'],\n",
    "            path='durak_deep_model_new.pt'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при конвертации модели: {e}\")\n",
    "\n",
    "    # 2. Теперь загружаем новую модель\n",
    "    try:\n",
    "        durak_ai = DurakModel('durak_deep_model.pt')\n",
    "        \n",
    "        test_state = {\n",
    "            'trump': '10H',\n",
    "            'player_hand': ['9S', '10D', '14H', '12C', '13D'],\n",
    "            'game_type': 0,\n",
    "            'deck': ['11S', '11C', '10C', '12H'],\n",
    "            'table': [],\n",
    "            'opponent_hand_count': 4\n",
    "        }\n",
    "        \n",
    "        decision = durak_ai.make_decision(test_state)\n",
    "        print(\"Принято решение:\", decision)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при работе модели: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
